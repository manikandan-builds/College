{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-RpPCa5BykR",
        "outputId": "e702a5db-e791-4266-a613-a0140945bd4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 1.0098\n",
            "Epoch [20/100], Loss: 0.7898\n",
            "Epoch [30/100], Loss: 0.5140\n",
            "Epoch [40/100], Loss: 0.3189\n",
            "Epoch [50/100], Loss: 0.1708\n",
            "Epoch [60/100], Loss: 0.0978\n",
            "Epoch [70/100], Loss: 0.0710\n",
            "Epoch [80/100], Loss: 0.0604\n",
            "Epoch [90/100], Loss: 0.0553\n",
            "Epoch [100/100], Loss: 0.0523\n",
            "Accuracy of the model on the test set: 96.67%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn,optim\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X = torch.from_numpy(X).float()\n",
        "y = torch.from_numpy(y)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)\n",
        "\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FFNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 10)  # Input layer to hidden layer\n",
        "        self.fc2 = nn.Linear(10, 10)  # Hidden layer to hidden layer\n",
        "        self.fc3 = nn.Linear(10, 3)   # Hidden layer to output layer\n",
        "        self.Tanh = nn.Tanh()         # Activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Tanh(self.fc1(x))    # First layer\n",
        "        x = self.Tanh(self.fc2(x))    # Second layer\n",
        "        x = self.fc3(x)                # Output layer\n",
        "        return x\n",
        "\n",
        "\n",
        "model = FFNN()\n",
        "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    outputs = model(X_train)  # Forward pass\n",
        "    loss = criterion(outputs, y_train)  # Compute the loss\n",
        "    loss.backward()  # Backward pass\n",
        "    optimizer.step()  # Update the weights\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)  # Forward pass\n",
        "    _, predicted = torch.max(outputs.data, 1)  # Get the predicted class\n",
        "    total = y_test.size(0)\n",
        "    correct = (predicted == y_test).sum().item()  # Count correct predictions\n",
        "\n",
        "print(f'Accuracy of the model on the test set: {100 * correct / total:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THR4dgI5ByuO",
        "outputId": "94032f3d-6d4e-439e-f953-ade461c8be43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [100/500], Loss: 1.0483\n",
            "Epoch [200/500], Loss: 0.9378\n",
            "Epoch [300/500], Loss: 0.9414\n",
            "Epoch [400/500], Loss: 0.8970\n",
            "Epoch [500/500], Loss: 0.8966\n",
            "Accuracy of the model on the test set: 53.33%\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "heart_disease = fetch_ucirepo(id=45)\n",
        "X = heart_disease.data.features\n",
        "y = heart_disease.data.targets\n",
        "\n",
        "df = pd.DataFrame(X)\n",
        "df['target'] = y\n",
        "df = df.dropna()\n",
        "\n",
        "df = pd.DataFrame(X)\n",
        "df['target'] = y\n",
        "df = df.dropna()\n",
        "\n",
        "\n",
        "X = df.drop(\"target\",axis=1).values\n",
        "y = df[\"target\"].values\n",
        "\n",
        "X = torch.from_numpy(X).float()\n",
        "y = torch.from_numpy(y)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)\n",
        "\n",
        "\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FFNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(13, 10)  # Input layer to hidden layer\n",
        "        self.fc2 = nn.Linear(10, 10)  # Hidden layer to hidden layer\n",
        "        self.fc3 = nn.Linear(10, 5)   # Hidden layer to output layer\n",
        "        self.Tanh = nn.Tanh()         # Activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Tanh(self.fc1(x))    # First layer\n",
        "        x = self.Tanh(self.fc2(x))    # Second layer\n",
        "        x = self.fc3(x)                # Output layer\n",
        "        return x\n",
        "\n",
        "model = FFNN()\n",
        "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    outputs = model(X_train)  # Forward pass\n",
        "    loss = criterion(outputs, y_train)  # Compute the loss\n",
        "    loss.backward()  # Backward pass\n",
        "    optimizer.step()  # Update the weights\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)  # Forward pass\n",
        "    _, predicted = torch.max(outputs.data, 1)  # Get the predicted class\n",
        "    total = y_test.size(0)\n",
        "    correct = (predicted == y_test).sum().item()  # Count correct predictions\n",
        "\n",
        "print(f'Accuracy of the model on the test set: {100 * correct / total:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niQR3JLLBWFd",
        "outputId": "747fc179-00e9-4526-f466-893af03295aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch [1/5], Loss: 0.3933\n",
            "Epoch [2/5], Loss: 0.1923\n",
            "Epoch [3/5], Loss: 0.1396\n",
            "Epoch [4/5], Loss: 0.1120\n",
            "Epoch [5/5], Loss: 0.0927\n",
            "Accuracy of the model on the test set: 97.29%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Convert to float and normalize (to match TensorFlow behavior)\n",
        "x_train, x_test = x_train.astype(np.float32) / 255.0, x_test.astype(np.float32) / 255.0\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train = torch.from_numpy(x_train).float()\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "X_test = torch.from_numpy(x_test).float()\n",
        "y_test = torch.from_numpy(y_test).long()\n",
        "\n",
        "# Define Neural Network\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FFNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()  # Flatten Layer\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input layer to hidden layer\n",
        "        self.relu = nn.ReLU()  # Activation function\n",
        "        self.dropout = nn.Dropout(0.2)  # Dropout Layer\n",
        "        self.fc2 = nn.Linear(128, 10)  # Hidden layer to output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)  # Use nn.Flatten()\n",
        "        x = self.relu(self.fc1(x))  # First layer with ReLU activation\n",
        "        x = self.dropout(x)  # Apply dropout\n",
        "        x = self.fc2(x)  # Output layer\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = FFNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop (without DataLoader)\n",
        "num_epochs = 5\n",
        "batch_size = 64\n",
        "num_samples = X_train.shape[0]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    # Mini-batch gradient descent\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        X_batch = X_train[i:i + batch_size]\n",
        "        y_batch = y_train[i:i + batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / (num_samples // batch_size):.4f}\")\n",
        "\n",
        "# Evaluation (without DataLoader)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = (predicted == y_test).float().mean().item() * 100\n",
        "\n",
        "print(f\"Accuracy of the model on the test set: {accuracy:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
